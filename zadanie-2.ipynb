{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn_evaluation import plot\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data_path = \"train_dummy.csv\"\n",
    "test_data_path = \"test_dummy.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path, low_memory=False)\n",
    "test_data = pd.read_csv(test_data_path, low_memory=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "scaled_train = scaler.transform(train_data)\n",
    "scaled_train_data = pd.DataFrame(scaled_train, columns=train_data.columns)\n",
    "scaled_test = scaler.transform(test_data)\n",
    "scaled_test_data = pd.DataFrame(scaled_test,columns=test_data.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_train_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x=scaled_train_data[\"LotArea\"], y=scaled_train_data['SalePrice'], )\n",
    "plt.xlabel('Lot Area')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x=scaled_train_data[\"LotArea\"], y=scaled_train_data['SalePrice'], )\n",
    "plt.xlabel('Lot Area')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Vypisanie najviac korelujucich hodnot\n",
    "corr = train_data.corr().abs()\n",
    "highest_corr = corr.unstack()\n",
    "sorted_highest_corr = highest_corr.sort_values(ascending=False).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.imshow(corr)\n",
    "fig.write_html(\"corr_matrix.html\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_train_data[\"LotArea\"].hist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "X_train = scaled_train_data.drop('SalePrice', axis=1)\n",
    "y_train = scaled_train_data['SalePrice']\n",
    "X_columns = scaled_train_data.drop('SalePrice', axis=1).columns\n",
    "X_test = scaled_test_data.drop('SalePrice', axis=1)\n",
    "y_test = scaled_test_data['SalePrice']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {'max_features': ['sqrt', 'log2',1.0],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'max_depth' : [5, 6, 7, 8, 9],\n",
    "              'criterion' :['squared_error', 'absolute_error'],\n",
    "              'min_samples_leaf': [1,2,3,4]\n",
    "             }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(estimator=regressor,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring=[\"r2\",\"neg_mean_squared_error\"],\n",
    "                           refit=\"r2\",\n",
    "                           cv=5, verbose=4)\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"BEST ESTIMATOR: \" + str(grid_search.best_estimator_))\n",
    "print(\"BEST SCORE: \" + str(grid_search.best_score_))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_results = pd.DataFrame(grid_search.cv_results_)\n",
    "tree_results = tree_results.sort_values(\"rank_test_r2\")\n",
    "tree_results.to_csv(\"tree_results.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_tree_regressor = DecisionTreeRegressor(ccp_alpha=0.001, criterion='absolute_error', max_depth=5,min_samples_leaf=2)\n",
    "best_tree_regressor.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = best_tree_regressor.predict(X_test)\n",
    "y_true = y_test\n",
    "plot.residuals(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_test_results = cross_validate(best_tree_regressor,X_test,y_test,scoring=[\"r2\",\"neg_mean_squared_error\"])\n",
    "tree_test_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_representation = tree.export_text(best_tree_regressor)\n",
    "feature_names = list(scaled_train_data.columns.values)\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(best_tree_regressor,feature_names= feature_names,\n",
    "                   filled=True)\n",
    "fig.savefig('decisionTree.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param = {'kernel' : ('linear', 'poly', 'rbf'),'C' : [1,5,10],'gamma' : (0.1,0.01,0.001)},\n",
    "\n",
    "svrGridSearch = GridSearchCV(estimator=SVR(),param_grid=param,\n",
    "                             cv=5,\n",
    "                             verbose=4,)\n",
    "\n",
    "svrGridSearch.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_scores = svrGridSearch.cv_results_\n",
    "tree_results = pd.DataFrame(grid_scores)\n",
    "#tree_results = tree_results.sort_values(\"rank_test_r2\")\n",
    "tree_results.to_csv(\"svm_results.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"BEST ESTIMATOR: \" + str(svrGridSearch.best_estimator_))\n",
    "print(\"BEST SCORE: \" + str(svrGridSearch.best_score_))\n",
    "print(\"BEST PARAMETERS\" + str(svrGridSearch.best_params_))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_test_results = cross_validate(best_tree_regressor,X_test,y_test,scoring=[\"r2\",\"neg_mean_squared_error\"])\n",
    "tree_test_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svrGridSearchResults = svrGridSearch.cv_results_\n",
    "ax = plot.grid_search(svrGridSearch.cv_results_, change=\"gamma\", kind='bar', sort=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn_evaluation import plot\n",
    "bestSvr = SVR(C=1,gamma='auto',kernel='rbf', verbose=False)\n",
    "bestSvr.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = bestSvr.predict(X_test)\n",
    "y_true = y_test\n",
    "plot.residuals(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svr_test_results = cross_validate(bestSvr,X_test,y_test,scoring=[\"r2\",\"neg_mean_squared_error\"], verbose=False)\n",
    "svr_test_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [1,2,3,4],\n",
    "}\n",
    "randomForestRegressor = RandomForestRegressor(random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=randomForestRegressor,\n",
    "                           param_grid=parameters,\n",
    "                           scoring=[\"r2\",\"neg_mean_squared_error\"],\n",
    "                           refit=\"r2\",\n",
    "                           cv=5, verbose=4)\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"BEST FOREST ESTIMATOR: \" + str(grid_search.best_estimator_))\n",
    "print(\"BEST SCORE: \" + str(grid_search.best_score_))\n",
    "print(\"BEST PARAMETERS\" + str(grid_search.best_params_))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bestRandomForest = RandomForestRegressor(max_depth=4,n_estimators=150, random_state=0)\n",
    "bestRandomForest.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = bestRandomForest.predict(X_test)\n",
    "y_true = y_test\n",
    "plot.residuals(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_test_results = cross_validate(bestRandomForest,X_test,y_test,scoring=[\"r2\",\"neg_mean_squared_error\"], verbose=False)\n",
    "forest_test_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(bestRandomForest.feature_importances_, index=X_train.columns).sort_values()\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(feat_importances, orientation='h')\n",
    "fig.write_html('importances.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = X_test\n",
    "y = y_test\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "y_pred = bestSvr.predict(X)\n",
    "\n",
    "fig = px.scatter(x=y, y=y_pred, labels={'x': 'ground truth', 'y': 'prediction'}, title=\"Prediction vs Expected SVR\")\n",
    "fig.add_shape(\n",
    "    type=\"line\", line=dict(dash='dash'),\n",
    "    x0=y.min(), y0=y.min(),\n",
    "    x1=y.max(), y1=y.max()\n",
    ")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = scaled_test_data\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "df['prediction'] = bestSvr.predict(X_test)\n",
    "df['residual'] = df['prediction'] - scaled_test_data['SalePrice']\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, x='prediction', y='residual',\n",
    "    marginal_y='violin', trendline='ols', title=\"Residual SVR\"\n",
    ")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = scaled_test_data\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "df['prediction'] = bestRandomForest.predict(X_test)\n",
    "df['residual'] = df['prediction'] - scaled_test_data['SalePrice']\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, x='prediction', y='residual',\n",
    "    marginal_y='violin', trendline='ols', title=\"Residual RandomForrest\"\n",
    ")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = scaled_test_data\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "df['prediction'] = best_tree_regressor.predict(X_test)\n",
    "df['residual'] = df['prediction'] - scaled_test_data['SalePrice']\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, x='prediction', y='residual',\n",
    "    marginal_y='violin', trendline='ols', title=\"Residual Tree\"\n",
    ")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(train_data, x='TotRmsAbvGrd', y='GrLivArea', z='YearBuilt',\n",
    "                    color='SalePrice', symbol='GarageCars')\n",
    "fig.update_layout(coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0,\n",
    "                                          ticks=\"outside\"))\n",
    "fig.update_layout(legend=dict(title_font_family=\"Times New Roman\",\n",
    "                              font=dict(size= 20)\n",
    "))\n",
    "fig.write_html('3d.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "import umap\n",
    "X = X_train\n",
    "reducer = umap.UMAP(n_components=3, min_dist=0.1, n_neighbors=50).fit(X)\n",
    "umap_train_data = reducer.transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.121225  ,  9.44216   ,  8.953572  ],\n       [ 2.6759725 ,  6.4464073 ,  8.116978  ],\n       [ 2.2482646 ,  6.9382234 ,  8.014394  ],\n       ...,\n       [-0.83388287, 10.246829  ,  8.005696  ],\n       [ 2.222857  ,  6.333964  ,  7.389529  ],\n       [-2.49231   , 10.547091  ,  7.8102474 ]], dtype=float32)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_train_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "df_umap = pd.DataFrame(umap_train_data)\n",
    "df_umap[['SalePrice','GarageCars']] = train_data[[\"SalePrice\",\"GarageCars\"]]\n",
    "fig = px.scatter_3d(df_umap, x=0, y=1, z=2,\n",
    "                    color='SalePrice', symbol='GarageCars')\n",
    "fig.update_layout(coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0,\n",
    "                                          ticks=\"outside\"))\n",
    "fig.update_layout(legend=dict(title_font_family=\"Times New Roman\",\n",
    "                              font=dict(size= 20)\n",
    "))\n",
    "fig.write_html('3d_umap.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "X = X_train\n",
    "pca = PCA(n_components=3)\n",
    "components = pca.fit_transform(X)\n",
    "\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    components, x=0, y=1, z=2, color=scaled_train_data['SalePrice'],\n",
    "    title=f'Total Explained Variance: {total_var:.2f}%',\n",
    "    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    ")\n",
    "fig.write_html('3d_pca.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range (0,255,5):\n",
    "    if i == 1:\n",
    "        continue\n",
    "    pca = PCA(n_components=i, random_state=2020)\n",
    "    components = pca.fit_transform(scaled_train_data)\n",
    "    print(\"VARIANCE EXPLAINED BY ALL \" + str(i) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POCET NAJVIAC KORELUJUCICH STLPCOV PRI 1000 HODNOTACH  186\n",
      "POCET NAJMENEJ KORELUJUCICH STLPCOV PRI 1000 HODNOTACH  69\n",
      "(940, 69)\n",
      "(940, 186)\n",
      "(154, 69)\n",
      "(154, 186)\n"
     ]
    }
   ],
   "source": [
    "most_corr_columns = sorted_highest_corr[:1000].reset_index()\n",
    "most_corr =[]\n",
    "reducted_train_data = X_train.copy()\n",
    "reducted_test_data = X_test.copy()\n",
    "for row in most_corr_columns['level_0']:\n",
    "    if row in reducted_train_data.columns:\n",
    "        reducted_train_data = reducted_train_data.drop(row, axis=1)\n",
    "        reducted_test_data = reducted_test_data.drop(row, axis=1)\n",
    "        most_corr.append(row)\n",
    "\n",
    "updated_most_corr = reducted_train_data.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "least_corr_train = X_train.drop(columns = most_corr)\n",
    "most_corr_train = X_train.drop(columns = least_corr_train.columns)\n",
    "\n",
    "least_corr_test = X_test.drop(columns = most_corr)\n",
    "most_corr_test = X_test.drop(columns = least_corr_test.columns)\n",
    "\n",
    "print(\"POCET NAJVIAC KORELUJUCICH STLPCOV PRI 1000 HODNOTACH \", len(most_corr_train.columns))\n",
    "print(\"POCET NAJMENEJ KORELUJUCICH STLPCOV PRI 1000 HODNOTACH \", len(least_corr_train.columns))\n",
    "print(least_corr_train.shape)\n",
    "print(most_corr_train.shape)\n",
    "print(least_corr_test.shape)\n",
    "print(most_corr_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 2 PRINCIPAL COMPONENTS = 26.222433433741408\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "pca2 = PCA(n_components=2, random_state=2020)\n",
    "pca2.fit(most_corr_train)\n",
    "train_components2 = pca2.transform(most_corr_train)\n",
    "test_components2 = pca2.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(2) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca2.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 2 PRINCIPAL COMPONENTS = 30.49236278370278\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "pca3 = PCA(n_components=3, random_state=2020)\n",
    "pca3.fit(most_corr_train)\n",
    "train_components3 = pca3.transform(most_corr_train)\n",
    "test_components3 = pca3.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(2) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca3.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 5 PRINCIPAL COMPONENTS = 37.76872793938907\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "pca5 = PCA(n_components=5, random_state=2020)\n",
    "pca5.fit(most_corr_train)\n",
    "train_components5 = pca5.transform(most_corr_train)\n",
    "test_components5 = pca5.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(5) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca5.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 10 PRINCIPAL COMPONENTS = 50.624255399688536\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "pca10 = PCA(n_components=10, random_state=2020)\n",
    "pca10.fit(most_corr_train)\n",
    "train_components10 = pca10.transform(most_corr_train)\n",
    "test_components10 = pca10.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(10) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca10.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 15 PRINCIPAL COMPONENTS = 60.070255944745504\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "pca15 = PCA(n_components=15, random_state=2020)\n",
    "pca15.fit(most_corr_train)\n",
    "train_components15 = pca15.transform(most_corr_train)\n",
    "test_components15 = pca15.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(15) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca15.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 30 PRINCIPAL COMPONENTS = 77.5127873512755\n"
     ]
    }
   ],
   "source": [
    "pca30 = PCA(n_components=30, random_state=2020)\n",
    "pca30.fit(most_corr_train)\n",
    "train_components30 = pca30.transform(most_corr_train)\n",
    "test_components30 = pca30.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(30) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca30.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE EXPLAINED BY ALL 60 PRINCIPAL COMPONENTS = 92.6132043045935\n"
     ]
    }
   ],
   "source": [
    "pca60 = PCA(n_components=60, random_state=2020)\n",
    "pca60.fit(most_corr_train)\n",
    "train_components60 = pca60.transform(most_corr_train)\n",
    "test_components60 = pca60.transform(most_corr_test)\n",
    "print(\"VARIANCE EXPLAINED BY ALL \" + str(60) + \" PRINCIPAL COMPONENTS = \" + str(sum(pca60.explained_variance_ratio_ *100)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "train_reductions = [train_components2,train_components3,train_components5,train_components10,train_components30,train_components60]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "test_reductions = [test_components2,test_components3,test_components5,test_components10,test_components30,test_components60]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(154, 2)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def train_with_reduction(train_p,test_p):\n",
    "    reducted_train_data_pca = least_corr_train.copy()\n",
    "    pca_reduction = pd.DataFrame(train_p)\n",
    "    ready_train = pd.concat([reducted_train_data_pca,pca_reduction], axis=1, join='inner')\n",
    "    ready_train.columns = ready_train.columns.map(str)\n",
    "    bestRandomForestPca = RandomForestRegressor(max_depth=4,n_estimators=150, random_state=2020)\n",
    "    bestRandomForestPca.fit(ready_train, y_train)\n",
    "    test_result_Best_random_forest_pca = cross_validate(bestRandomForestPca,test_p,y_test,scoring=[\"r2\",\"neg_mean_squared_error\"])\n",
    "    print(\"Pocet priznakov: \" + str(len(ready_train.columns)) + \" Pocet dimenzii redukovanej podmnoziny: \" + str(len(pca_reduction.columns)))\n",
    "    print(test_result_Best_random_forest_pca)\n",
    "    print('\\n')\n",
    "    return [len(pca_reduction.columns),test_result_Best_random_forest_pca]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pocet priznakov: 71 Pocet dimenzii redukovanej podmnoziny: 2\n",
      "{'fit_time': array([0.23605299, 0.22405005, 0.11002493, 0.10802507, 0.10702348]), 'score_time': array([0.14103222, 0.01100278, 0.00700235, 0.0070014 , 0.00800204]), 'test_r2': array([0.27718441, 0.44501604, 0.49367965, 0.55188087, 0.34811876]), 'test_neg_mean_squared_error': array([-0.00466225, -0.0075442 , -0.00460516, -0.00620766, -0.00892609])}\n",
      "\n",
      "\n",
      "Pocet priznakov: 72 Pocet dimenzii redukovanej podmnoziny: 3\n",
      "{'fit_time': array([0.11002564, 0.11702514, 0.11002493, 0.10502291, 0.11302567]), 'score_time': array([0.00900316, 0.00900197, 0.00700188, 0.00800252, 0.00700164]), 'test_r2': array([0.33205729, 0.57753427, 0.52782566, 0.75713148, 0.66700028]), 'test_neg_mean_squared_error': array([-0.00430831, -0.00574281, -0.00429459, -0.00336438, -0.00455971])}\n",
      "\n",
      "\n",
      "Pocet priznakov: 74 Pocet dimenzii redukovanej podmnoziny: 5\n",
      "{'fit_time': array([0.12302804, 0.10902476, 0.10802484, 0.11402559, 0.10702443]), 'score_time': array([0.0070014 , 0.00800157, 0.00800157, 0.00700188, 0.00700188]), 'test_r2': array([0.45732009, 0.63221832, 0.63229726, 0.80052286, 0.70555594]), 'test_neg_mean_squared_error': array([-0.00350035, -0.00499946, -0.00334438, -0.0027633 , -0.00403177])}\n",
      "\n",
      "\n",
      "Pocet priznakov: 79 Pocet dimenzii redukovanej podmnoziny: 10\n",
      "{'fit_time': array([0.11602664, 0.11902761, 0.11802626, 0.11902666, 0.11702752]), 'score_time': array([0.008003  , 0.0070014 , 0.0080018 , 0.00700212, 0.00699973]), 'test_r2': array([0.46755184, 0.64477718, 0.53649929, 0.77762818, 0.76545838]), 'test_neg_mean_squared_error': array([-0.00343435, -0.00482874, -0.0042157 , -0.00308045, -0.00321154])}\n",
      "\n",
      "\n",
      "Pocet priznakov: 99 Pocet dimenzii redukovanej podmnoziny: 30\n",
      "{'fit_time': array([0.15603542, 0.16403699, 0.15903616, 0.17403984, 0.16403723]), 'score_time': array([0.00700212, 0.00900197, 0.00700164, 0.00800157, 0.0070014 ]), 'test_r2': array([0.31068953, 0.60555935, 0.56921393, 0.72359993, 0.71078335]), 'test_neg_mean_squared_error': array([-0.00444613, -0.00536185, -0.00391815, -0.00382889, -0.00396019])}\n",
      "\n",
      "\n",
      "Pocet priznakov: 129 Pocet dimenzii redukovanej podmnoziny: 60\n",
      "{'fit_time': array([0.2170496 , 0.22004986, 0.22104979, 0.21504807, 0.21804929]), 'score_time': array([0.00800133, 0.0080018 , 0.00700188, 0.00700188, 0.00700164]), 'test_r2': array([0.39495682, 0.63732613, 0.60545622, 0.67588519, 0.70031215]), 'test_neg_mean_squared_error': array([-0.0039026 , -0.00493002, -0.00358851, -0.00448986, -0.00410357])}\n",
      "\n",
      "\n",
      "[0.15703530311584474, 0.11102485656738281, 0.11222553253173828, 0.11782693862915039, 0.1634371280670166, 0.21824932098388672]\n",
      "[2, 3, 5, 10, 30, 60]\n",
      "[0.423175945065872, 0.5723097950184147, 0.6455828930068078, 0.6383829731709891, 0.5839692187049831, 0.6027873016295245]\n"
     ]
    }
   ],
   "source": [
    "fit_times = []\n",
    "dimensions = []\n",
    "r2score = []\n",
    "for (train, test) in zip(train_reductions, test_reductions):\n",
    "     result = train_with_reduction(train,test)\n",
    "     fit_times.append(result[1]['fit_time'].mean())\n",
    "     dimensions.append(result[0])\n",
    "     r2score.append(result[1]['test_r2'].mean())\n",
    "print(fit_times)\n",
    "print(dimensions)\n",
    "print(r2score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(dimensions, fit_times, r2score)),\n",
    "               columns =['dimension', 'fit_time','r2score'])\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=dimensions, y=fit_times, name=\"Mean Fit time\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=dimensions, y=r2score, name=\"Mean R2 score\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"R2 Score with Fit times based on reductions\"\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text=\"Dimensions\")\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"Fit time\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"R2 score\", secondary_y=True)\n",
    "\n",
    "fig.write_html('reducted_dimension.html')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
